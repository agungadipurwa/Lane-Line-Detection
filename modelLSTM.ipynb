{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adiag\\AppData\\Local\\Temp\\ipykernel_36616\\1026359757.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df11 = pd.concat(dfs1, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all txt files\n",
    "files = glob.glob('C:\\D\\SKRIPSI\\yolov5\\\\runs\\detect\\inference_10\\labels\\*.txt')\n",
    "\n",
    "# Read each file into a DataFrame and store the DataFrames in a list\n",
    "dfs1 = [pd.read_csv(file, sep=\" \") for file in files]\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df11 = pd.concat(dfs1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.704687</th>\n",
       "      <th>0.9875</th>\n",
       "      <th>0.040625</th>\n",
       "      <th>0.025</th>\n",
       "      <th>0.513281</th>\n",
       "      <th>0.171094</th>\n",
       "      <th>0.0390625</th>\n",
       "      <th>0.0859375</th>\n",
       "      <th>0.0398437</th>\n",
       "      <th>...</th>\n",
       "      <th>0.51875</th>\n",
       "      <th>0.728906</th>\n",
       "      <th>0.60625</th>\n",
       "      <th>0.650781</th>\n",
       "      <th>0.651563</th>\n",
       "      <th>0.754687</th>\n",
       "      <th>0.89375</th>\n",
       "      <th>0.319531</th>\n",
       "      <th>0.517187</th>\n",
       "      <th>0.128906</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.510938</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.544531</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>0.042188</td>\n",
       "      <td>0.092188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.615625</td>\n",
       "      <td>0.575781</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.160938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.167187</td>\n",
       "      <td>0.470313</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.134375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096094</td>\n",
       "      <td>0.885156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.292188</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089063</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336719</td>\n",
       "      <td>0.519531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>673 rows Ã— 383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  0.704687    0.9875  0.040625     0.025  0.513281  0.171094  0.0390625  \\\n",
       "0    0  0.510938  0.125000  0.031250  0.065625       NaN       NaN        NaN   \n",
       "1    0  0.544531  0.277344  0.042188  0.092188       NaN       NaN        NaN   \n",
       "2    0  0.078125  0.910156  0.078125  0.179688       NaN       NaN        NaN   \n",
       "3    0  0.615625  0.575781  0.068750  0.160938       NaN       NaN        NaN   \n",
       "4    0  0.167187  0.470313  0.053125  0.134375       NaN       NaN        NaN   \n",
       "..  ..       ...       ...       ...       ...       ...       ...        ...   \n",
       "668  0       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "669  0       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "670  0       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "671  0       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "672  0       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "     0.0859375  0.0398437  ...  0.51875  0.728906   0.60625  0.650781  \\\n",
       "0          NaN        NaN  ...      NaN       NaN       NaN       NaN   \n",
       "1          NaN        NaN  ...      NaN       NaN       NaN       NaN   \n",
       "2          NaN        NaN  ...      NaN       NaN       NaN       NaN   \n",
       "3          NaN        NaN  ...      NaN       NaN       NaN       NaN   \n",
       "4          NaN        NaN  ...      NaN       NaN       NaN       NaN   \n",
       "..         ...        ...  ...      ...       ...       ...       ...   \n",
       "668        NaN        NaN  ...      NaN       NaN  0.096094  0.885156   \n",
       "669        NaN        NaN  ...      NaN       NaN       NaN       NaN   \n",
       "670        NaN        NaN  ...      NaN       NaN       NaN       NaN   \n",
       "671        NaN        NaN  ...      NaN       NaN       NaN       NaN   \n",
       "672        NaN        NaN  ...      NaN       NaN       NaN       NaN   \n",
       "\n",
       "     0.651563  0.754687   0.89375  0.319531  0.517187  0.128906  \n",
       "0         NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1         NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2         NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "3         NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4         NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "668       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "669  0.292188  0.335938       NaN       NaN       NaN       NaN  \n",
       "670  0.089063  0.946875       NaN       NaN       NaN       NaN  \n",
       "671       NaN       NaN  0.382812       NaN       NaN       NaN  \n",
       "672       NaN       NaN       NaN       NaN  0.336719  0.519531  \n",
       "\n",
       "[673 rows x 383 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('C:\\D\\SKRIPSI\\yolov5\\\\runs\\detect\\inference_10\\labels\\*.txt')\n",
    "\n",
    "data = [pd.read_csv(file, sep=\" \", names=['class','x', 'y', 'w','h']) for file in files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   class         x         y         w         h\n",
       " 0      0  0.704687  0.987500  0.040625  0.025000\n",
       " 1      0  0.510938  0.125000  0.031250  0.065625\n",
       " 2      0  0.544531  0.277344  0.042188  0.092188\n",
       " 3      0  0.078125  0.910156  0.078125  0.179688\n",
       " 4      0  0.615625  0.575781  0.068750  0.160938\n",
       " 5      0  0.167187  0.470313  0.053125  0.134375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.513281  0.171094  0.039062  0.085938\n",
       " 1      0  0.560938  0.360938  0.050000  0.109375\n",
       " 2      0  0.194531  0.312500  0.042188  0.100000\n",
       " 3      0  0.661719  0.745313  0.089063  0.212500\n",
       " 4      0  0.145313  0.607031  0.062500  0.173438,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.039844  0.594531  0.060937  0.117188\n",
       " 1      0  0.174219  0.423438  0.045312  0.118750\n",
       " 2      0  0.528125  0.242969  0.046875  0.098437\n",
       " 3      0  0.729688  0.938281  0.084375  0.123438\n",
       " 4      0  0.596094  0.485156  0.067187  0.145313\n",
       " 5      0  0.119531  0.832031  0.064062  0.229687,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.190625  0.277344  0.028125  0.079687\n",
       " 1      0  0.113281  0.979688  0.039062  0.040625\n",
       " 2      0  0.017188  0.778125  0.034375  0.146875\n",
       " 3      0  0.554688  0.326562  0.053125  0.112500\n",
       " 4      0  0.160938  0.560156  0.050000  0.154687\n",
       " 5      0  0.646094  0.641406  0.082812  0.185937,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.723437  0.846875  0.118750  0.243750\n",
       " 1      0  0.596875  0.425781  0.068750  0.151562\n",
       " 2      0  0.190625  0.364062  0.037500  0.112500\n",
       " 3      0  0.153906  0.739844  0.054688  0.204688,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.803125  0.982031  0.056250  0.035937\n",
       " 1      0  0.165625  0.922656  0.056250  0.154687\n",
       " 2      0  0.206250  0.481250  0.040625  0.134375\n",
       " 3      0  0.671094  0.565625  0.085938  0.187500,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.667188  0.389844  0.062500  0.120312\n",
       " 1      0  0.598437  0.149219  0.046875  0.089063\n",
       " 2      0  0.789844  0.768750  0.114063  0.231250\n",
       " 3      0  0.241406  0.642969  0.045312  0.173438,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.346875  0.196875  0.028125  0.106250\n",
       " 1      0  0.772656  0.510938  0.079687  0.150000\n",
       " 2      0  0.361719  0.035937  0.020313  0.065625\n",
       " 3      0  0.682031  0.218750  0.051562  0.100000\n",
       " 4      0  0.293750  0.850781  0.046875  0.229687\n",
       " 5      0  0.915625  0.923437  0.100000  0.153125\n",
       " 6      0  0.327344  0.437500  0.039062  0.131250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.713281  0.114063  0.039062  0.075000\n",
       " 1      0  0.910937  0.696094  0.090625  0.135937\n",
       " 2      0  0.421875  0.075781  0.018750  0.070312\n",
       " 3      0  0.367969  0.984375  0.042188  0.031250\n",
       " 4      0  0.410156  0.269531  0.029687  0.126563\n",
       " 5      0  0.782031  0.307031  0.060937  0.120312\n",
       " 6      0  0.393750  0.568750  0.040625  0.171875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.492969  0.017188  0.020313  0.031250\n",
       " 1      0  0.489844  0.140625  0.020313  0.081250\n",
       " 2      0  0.477344  0.771094  0.039062  0.226562\n",
       " 3      0  0.813281  0.189844  0.045312  0.089063\n",
       " 4      0  0.485156  0.378906  0.029687  0.148438\n",
       " 5      0  0.904688  0.426562  0.087500  0.146875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.579687  0.957031  0.040625  0.085938\n",
       " 1      0  0.555469  0.221094  0.020313  0.104687\n",
       " 2      0  0.565625  0.525000  0.037500  0.193750\n",
       " 3      0  0.917969  0.284375  0.060937  0.109375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.599219  0.300781  0.029687  0.120312\n",
       " 1      0  0.628906  0.682813  0.054688  0.240625,\n",
       "    class        x         y         w         h\n",
       " 0      0  0.69375  0.866406  0.078125  0.267188\n",
       " 1      0  0.63125  0.394531  0.040625  0.142188,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.617188  0.235938  0.034375  0.096875\n",
       " 1      0  0.752344  0.972656  0.067187  0.054688\n",
       " 2      0  0.663281  0.510156  0.064062  0.176563,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.620313  0.314844  0.043750  0.104687\n",
       " 1      0  0.692969  0.654688  0.079687  0.221875,\n",
       "    class         x         y         w        h\n",
       " 0      0  0.739062  0.853125  0.109375  0.27500\n",
       " 1      0  0.624219  0.418750  0.057813  0.13125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.553125  0.241406  0.043750  0.104687\n",
       " 1      0  0.760156  0.960938  0.073438  0.078125\n",
       " 2      0  0.635938  0.539062  0.078125  0.159375,\n",
       "    class         x         y        w         h\n",
       " 0      0  0.551562  0.325781  0.05000  0.110937\n",
       " 1      0  0.665625  0.692969  0.09375  0.198437,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.483594  0.177344  0.048438  0.092188\n",
       " 1      0  0.564844  0.423438  0.064062  0.140625,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.595312  0.557031  0.081250  0.170312\n",
       " 1      0  0.489844  0.253906  0.051562  0.104687,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.317969  0.926562  0.029687  0.053125\n",
       " 1      0  0.511719  0.342187  0.067187  0.121875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.721094  0.924219  0.101562  0.151562\n",
       " 1      0  0.549219  0.466406  0.079687  0.154687,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.477344  0.282813  0.060937  0.115625\n",
       " 1      0  0.601562  0.617969  0.093750  0.198437,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.687500  0.825000  0.128125  0.250000\n",
       " 1      0  0.511719  0.380469  0.076563  0.142188,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.742969  0.966406  0.085938  0.067187\n",
       " 1      0  0.558594  0.501562  0.092188  0.175000,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.487500  0.317187  0.071875  0.134375\n",
       " 1      0  0.621094  0.671875  0.114063  0.240625,\n",
       "    class         x         y         w       h\n",
       " 0      0  0.529688  0.428125  0.084375  0.1625,\n",
       "    class       x         y    w         h\n",
       " 0      0  0.5875  0.577344  0.1  0.214062,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.514844  0.389062  0.073438  0.128125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.728125  0.932813  0.103125  0.134375\n",
       " 1      0  0.567187  0.525000  0.087500  0.168750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.642187  0.714063  0.109375  0.228125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.721094  0.912500  0.110937  0.175000\n",
       " 1      0  0.553125  0.480469  0.084375  0.167187,\n",
       "    class         x         y         w      h\n",
       " 0      0  0.621875  0.659375  0.103125  0.225,\n",
       "    class         x         y       w         h\n",
       " 0      0  0.709375  0.891406  0.1250  0.217187\n",
       " 1      0  0.532812  0.436719  0.0875  0.160938,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.880469  0.337500  0.101562  0.115625\n",
       " 1      0  0.942969  0.760156  0.114063  0.164062\n",
       " 2      0  0.596875  0.600781  0.096875  0.198437,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.285156  0.014063  0.026562  0.025000\n",
       " 1      0  0.695312  0.853906  0.137500  0.257812\n",
       " 2      0  0.520312  0.398438  0.062500  0.118750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.574219  0.541406  0.092188  0.179688,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.313281  0.114063  0.039062  0.087500\n",
       " 1      0  0.650781  0.742969  0.114063  0.242188,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.336719  0.198437  0.045312  0.100000\n",
       " 1      0  0.548437  0.457812  0.087500  0.175000\n",
       " 2      0  0.868750  0.289844  0.096875  0.117188\n",
       " 3      0  0.253906  0.026562  0.029687  0.053125\n",
       " 4      0  0.735937  0.943750  0.093750  0.112500,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.246875  0.232031  0.031250  0.095312\n",
       " 1      0  0.405469  0.054688  0.051562  0.100000\n",
       " 2      0  0.360156  0.297656  0.051562  0.117188\n",
       " 3      0  0.618750  0.627344  0.109375  0.223438,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.261719  0.337500  0.035937  0.115625\n",
       " 1      0  0.433594  0.123438  0.057813  0.115625\n",
       " 2      0  0.392969  0.416406  0.067187  0.157813,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.281250  0.467187  0.040625  0.140625\n",
       " 1      0  0.921875  0.364062  0.109375  0.131250\n",
       " 2      0  0.757812  0.969531  0.084375  0.060937\n",
       " 3      0  0.432031  0.571875  0.079687  0.190625\n",
       " 4      0  0.580469  0.513281  0.095312  0.195312,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.417969  0.073438  0.051562  0.100000\n",
       " 1      0  0.478906  0.769531  0.095312  0.245312\n",
       " 2      0  0.644531  0.696094  0.117188  0.223438,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.519531  0.930469  0.079687  0.139062\n",
       " 1      0  0.444531  0.146875  0.054688  0.109375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.471094  0.227344  0.064062  0.117188\n",
       " 1      0  0.596875  0.579687  0.106250  0.218750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.506250  0.338281  0.078125  0.151562\n",
       " 1      0  0.928906  0.735937  0.142188  0.143750\n",
       " 2      0  0.417969  0.090625  0.048438  0.100000,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.542969  0.450781  0.085938  0.167187\n",
       " 1      0  0.721094  0.911719  0.110937  0.176563\n",
       " 2      0  0.437500  0.160156  0.053125  0.114063\n",
       " 3      0  0.333594  0.225000  0.045312  0.106250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.459375  0.232812  0.062500  0.125000\n",
       " 1      0  0.349219  0.309375  0.051562  0.121875\n",
       " 2      0  0.592969  0.586719  0.101562  0.214062,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.485938  0.316406  0.078125  0.151562\n",
       " 1      0  0.643750  0.746875  0.134375  0.243750\n",
       " 2      0  0.367969  0.411719  0.057813  0.145313,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.250781  0.435156  0.035937  0.132812\n",
       " 1      0  0.694531  0.892969  0.114063  0.214062\n",
       " 2      0  0.391406  0.532812  0.070312  0.171875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.419531  0.682813  0.082812  0.212500\n",
       " 1      0  0.553125  0.539844  0.100000  0.201562,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.453125  0.860937  0.100000  0.256250\n",
       " 1      0  0.599219  0.689062  0.117188  0.240625,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.472656  0.971875  0.048438  0.056250\n",
       " 1      0  0.264844  0.341406  0.042188  0.114063,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.056250  0.964063  0.037500  0.071875\n",
       " 1      0  0.696094  0.959375  0.076563  0.081250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.364062  0.151562  0.075000  0.100000\n",
       " 1      0  0.046094  0.057813  0.039062  0.103125\n",
       " 2      0  0.564062  0.656250  0.090625  0.125000,\n",
       "    class         x         y         w        h\n",
       " 0      0  0.631250  0.848437  0.075000  0.10625\n",
       " 1      0  0.395312  0.120312  0.071875  0.08750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.053906  0.174219  0.051562  0.117188\n",
       " 1      0  0.416406  0.176563  0.089063  0.103125\n",
       " 2      0  0.411719  0.295312  0.089063  0.125000\n",
       " 3      0  0.016406  0.299219  0.029687  0.126563,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.014844  0.375781  0.029687  0.145313\n",
       " 1      0  0.054688  0.235156  0.059375  0.129688,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.479688  0.459375  0.118750  0.159375\n",
       " 1      0  0.014063  0.467969  0.028125  0.173438\n",
       " 2      0  0.114844  0.463281  0.073438  0.173438\n",
       " 3      0  0.357031  0.457812  0.101562  0.171875\n",
       " 4      0  0.379687  0.087500  0.050000  0.100000\n",
       " 5      0  0.060156  0.300781  0.067187  0.145313\n",
       " 6      0  0.237500  0.460938  0.087500  0.175000,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.389844  0.573438  0.107813  0.218750\n",
       " 1      0  0.858594  0.395312  0.135937  0.150000\n",
       " 2      0  0.413281  0.385938  0.089063  0.146875\n",
       " 3      0  0.014844  0.580469  0.029687  0.210938\n",
       " 4      0  0.062500  0.386719  0.068750  0.167187\n",
       " 5      0  0.407813  0.135937  0.053125  0.109375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.199219  0.486719  0.089063  0.189063\n",
       " 1      0  0.570312  0.491406  0.118750  0.182812\n",
       " 2      0  0.279687  0.710938  0.100000  0.253125\n",
       " 3      0  0.439844  0.199219  0.054688  0.114063\n",
       " 4      0  0.446094  0.489062  0.104687  0.181250\n",
       " 5      0  0.322656  0.491406  0.095312  0.182812,\n",
       "    class         x         y         w        h\n",
       " 0      0  0.349219  0.618750  0.114063  0.21875\n",
       " 1      0  0.472656  0.275000  0.057813  0.12500\n",
       " 2      0  0.403125  0.064062  0.043750  0.08750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.146094  0.960156  0.120312  0.070312\n",
       " 1      0  0.009375  0.967188  0.015625  0.065625\n",
       " 2      0  0.328906  0.960156  0.123438  0.079687\n",
       " 3      0  0.427344  0.125781  0.045312  0.098437\n",
       " 4      0  0.498437  0.957812  0.143750  0.078125\n",
       " 5      0  0.675000  0.957031  0.150000  0.079687\n",
       " 6      0  0.847656  0.955469  0.164062  0.082812\n",
       " 7      0  0.508594  0.365625  0.076563  0.150000,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.876562  0.332812  0.109375  0.134375\n",
       " 1      0  0.450000  0.196875  0.050000  0.106250\n",
       " 2      0  0.546094  0.474219  0.089063  0.176563,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.410937  0.086719  0.040625  0.082812\n",
       " 1      0  0.478125  0.285156  0.062500  0.123438\n",
       " 2      0  0.596875  0.626562  0.100000  0.212500,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.430469  0.162500  0.051562  0.096875\n",
       " 1      0  0.667969  0.835156  0.145313  0.257812\n",
       " 2      0  0.510938  0.397656  0.075000  0.142188,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.450781  0.239063  0.054688  0.112500\n",
       " 1      0  0.549219  0.523438  0.089063  0.175000\n",
       " 2      0  0.714063  0.954687  0.081250  0.090625,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.403906  0.123438  0.039062  0.078125\n",
       " 1      0  0.472656  0.323438  0.064062  0.128125\n",
       " 2      0  0.598437  0.677344  0.103125  0.223438,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.808594  0.292188  0.098437  0.121875\n",
       " 1      0  0.420312  0.187500  0.046875  0.090625\n",
       " 2      0  0.504687  0.422656  0.078125  0.151562,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.707031  0.972656  0.079687  0.051562\n",
       " 1      0  0.871094  0.382031  0.114063  0.142188\n",
       " 2      0  0.440625  0.257812  0.056250  0.106250\n",
       " 3      0  0.543750  0.546875  0.090625  0.190625,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.755469  0.234375  0.079687  0.096875\n",
       " 1      0  0.393750  0.139844  0.046875  0.095312\n",
       " 2      0  0.466406  0.343750  0.064062  0.125000\n",
       " 3      0  0.595312  0.703906  0.106250  0.232812,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.655469  0.882031  0.120312  0.217187\n",
       " 1      0  0.812500  0.317969  0.096875  0.117188\n",
       " 2      0  0.413281  0.209375  0.054688  0.109375\n",
       " 3      0  0.499219  0.451562  0.076563  0.153125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.371094  0.098437  0.045312  0.087500\n",
       " 1      0  0.884375  0.422656  0.109375  0.135937\n",
       " 2      0  0.438281  0.293750  0.067187  0.128125\n",
       " 3      0  0.546094  0.596094  0.092188  0.192188,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.954687  0.531250  0.090625  0.109375\n",
       " 1      0  0.392188  0.164062  0.050000  0.093750\n",
       " 2      0  0.470313  0.397656  0.071875  0.151562\n",
       " 3      0  0.609375  0.782031  0.115625  0.239063,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.415625  0.243750  0.056250  0.112500\n",
       " 1      0  0.668750  0.938281  0.093750  0.123438\n",
       " 2      0  0.514844  0.527344  0.092188  0.179688,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.449219  0.348437  0.064062  0.134375\n",
       " 1      0  0.576563  0.720312  0.112500  0.243750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.635156  0.895312  0.110937  0.209375\n",
       " 1      0  0.390625  0.208594  0.050000  0.095312\n",
       " 2      0  0.482812  0.464844  0.084375  0.167187,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.339844  0.116406  0.035937  0.064062\n",
       " 1      0  0.407031  0.292969  0.060937  0.110937\n",
       " 2      0  0.523438  0.621875  0.093750  0.209375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.577344  0.830469  0.126563  0.270312\n",
       " 1      0  0.421094  0.398438  0.067187  0.131250\n",
       " 2      0  0.343750  0.187500  0.043750  0.078125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.285937  0.122656  0.034375  0.060937\n",
       " 1      0  0.610156  0.175781  0.076563  0.085938\n",
       " 2      0  0.609375  0.974219  0.068750  0.051562\n",
       " 3      0  0.342187  0.267188  0.053125  0.090625\n",
       " 4      0  0.442969  0.538281  0.092188  0.170312,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.633594  0.264062  0.085938  0.106250\n",
       " 1      0  0.275000  0.190625  0.037500  0.068750\n",
       " 2      0  0.473437  0.738281  0.106250  0.235938\n",
       " 3      0  0.342187  0.374219  0.062500  0.114063,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.665625  0.363281  0.100000  0.110937\n",
       " 1      0  0.212500  0.131250  0.034375  0.068750\n",
       " 2      0  0.261719  0.272656  0.048438  0.085938\n",
       " 3      0  0.492969  0.925000  0.095312  0.150000\n",
       " 4      0  0.344531  0.507812  0.082812  0.150000,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.706250  0.482812  0.121875  0.137500\n",
       " 1      0  0.964844  0.838281  0.070312  0.092188\n",
       " 2      0  0.530469  0.257031  0.082812  0.092188\n",
       " 3      0  0.189844  0.188281  0.039062  0.082812\n",
       " 4      0  0.249219  0.366406  0.057813  0.104687\n",
       " 5      0  0.350000  0.675781  0.090625  0.189063,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.097656  0.014063  0.026562  0.028125\n",
       " 1      0  0.548437  0.342969  0.087500  0.107813\n",
       " 2      0  0.128906  0.110937  0.035937  0.071875\n",
       " 3      0  0.172656  0.258594  0.048438  0.095312\n",
       " 4      0  0.241406  0.482812  0.064062  0.131250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.075781  0.033594  0.029687  0.054688\n",
       " 1      0  0.435156  0.227344  0.067187  0.098437\n",
       " 2      0  0.582812  0.449219  0.106250  0.132812\n",
       " 3      0  0.108594  0.160156  0.039062  0.079687\n",
       " 4      0  0.157813  0.337500  0.053125  0.118750\n",
       " 5      0  0.239063  0.632031  0.081250  0.170312,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.910156  0.989844  0.051562  0.020313\n",
       " 1      0  0.055469  0.063281  0.032813  0.073438\n",
       " 2      0  0.458594  0.300781  0.076563  0.110937\n",
       " 3      0  0.640625  0.589063  0.118750  0.171875\n",
       " 4      0  0.092188  0.213281  0.043750  0.095312\n",
       " 5      0  0.148438  0.439844  0.059375  0.145313\n",
       " 6      0  0.246875  0.840625  0.090625  0.237500,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.371094  0.171094  0.064062  0.095312\n",
       " 1      0  0.229687  0.983594  0.040625  0.032813\n",
       " 2      0  0.497656  0.392969  0.095312  0.135937\n",
       " 3      0  0.041406  0.096094  0.029687  0.076563\n",
       " 4      0  0.081250  0.287500  0.046875  0.115625\n",
       " 5      0  0.144531  0.574219  0.070312  0.185937,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.014844  0.028906  0.026562  0.054688\n",
       " 1      0  0.796094  0.948438  0.104687  0.103125\n",
       " 2      0  0.554688  0.525000  0.109375  0.168750\n",
       " 3      0  0.402344  0.239844  0.073438  0.107813\n",
       " 4      0  0.035156  0.150000  0.035937  0.087500\n",
       " 5      0  0.078125  0.385938  0.050000  0.146875\n",
       " 6      0  0.145313  0.763281  0.078125  0.248437,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.017188  0.073438  0.025000  0.065625\n",
       " 1      0  0.642969  0.710156  0.129688  0.207813\n",
       " 2      0  0.036719  0.221094  0.035937  0.104687\n",
       " 3      0  0.079687  0.517969  0.056250  0.182812\n",
       " 4      0  0.450781  0.334375  0.089063  0.134375\n",
       " 5      0  0.143750  0.932031  0.062500  0.135937,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.014844  0.024219  0.023438  0.048438\n",
       " 1      0  0.377344  0.200000  0.064062  0.100000\n",
       " 2      0  0.025781  0.137500  0.026562  0.075000\n",
       " 3      0  0.085938  0.713281  0.062500  0.239063\n",
       " 4      0  0.044531  0.321094  0.035937  0.129688\n",
       " 5      0  0.514844  0.467187  0.104687  0.165625,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.339844  0.134375  0.045312  0.071875\n",
       " 1      0  0.039844  0.225000  0.026562  0.087500\n",
       " 2      0  0.032813  0.085156  0.018750  0.067187\n",
       " 3      0  0.091406  0.912500  0.054688  0.175000\n",
       " 4      0  0.597656  0.657031  0.117188  0.220313\n",
       " 5      0  0.432031  0.310937  0.079687  0.112500\n",
       " 6      0  0.053906  0.460156  0.035937  0.167187,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.678125  0.830469  0.100000  0.123438\n",
       " 1      0  0.045312  0.032813  0.021875  0.062500\n",
       " 2      0  0.389844  0.227344  0.054688  0.089063\n",
       " 3      0  0.052344  0.165625  0.020313  0.075000\n",
       " 4      0  0.071094  0.645312  0.042188  0.218750\n",
       " 5      0  0.494531  0.445312  0.089063  0.143750\n",
       " 6      0  0.057813  0.343750  0.028125  0.106250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.084375  0.871875  0.043750  0.256250\n",
       " 1      0  0.066406  0.096875  0.020313  0.075000\n",
       " 2      0  0.071875  0.256250  0.021875  0.090625\n",
       " 3      0  0.075000  0.484375  0.031250  0.131250\n",
       " 4      0  0.445312  0.336719  0.062500  0.104687\n",
       " 5      0  0.574219  0.620313  0.101562  0.184375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.077344  0.026562  0.020313  0.053125\n",
       " 1      0  0.668750  0.846875  0.137500  0.231250\n",
       " 2      0  0.084375  0.164062  0.021875  0.081250\n",
       " 3      0  0.408594  0.245312  0.054688  0.093750\n",
       " 4      0  0.087500  0.357031  0.028125  0.114063\n",
       " 5      0  0.087500  0.656250  0.034375  0.171875\n",
       " 6      0  0.507812  0.464063  0.084375  0.131250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.091406  0.064844  0.020313  0.076563\n",
       " 1      0  0.096094  0.235156  0.023438  0.104687\n",
       " 2      0  0.099219  0.476562  0.032813  0.140625\n",
       " 3      0  0.096094  0.880469  0.042188  0.235938\n",
       " 4      0  0.457812  0.336719  0.068750  0.110937\n",
       " 5      0  0.577344  0.617969  0.095312  0.167187,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.099219  0.104687  0.020313  0.087500\n",
       " 1      0  0.103906  0.312500  0.026562  0.118750\n",
       " 2      0  0.667969  0.824219  0.120312  0.232812\n",
       " 3      0  0.103906  0.628125  0.035937  0.187500\n",
       " 4      0  0.510938  0.438281  0.081250  0.139062,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.742969  0.977344  0.079687  0.042188\n",
       " 1      0  0.457031  0.272656  0.060937  0.117188\n",
       " 2      0  0.099219  0.015625  0.023438  0.028125\n",
       " 3      0  0.104687  0.829687  0.043750  0.259375\n",
       " 4      0  0.102344  0.158594  0.023438  0.101562\n",
       " 5      0  0.573438  0.575781  0.093750  0.179688\n",
       " 6      0  0.106250  0.410156  0.028125  0.145313,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.100781  0.037500  0.023438  0.075000\n",
       " 1      0  0.103906  0.982813  0.039062  0.034375\n",
       " 2      0  0.660937  0.778125  0.118750  0.225000\n",
       " 3      0  0.104687  0.555469  0.034375  0.182812\n",
       " 4      0  0.102344  0.232812  0.029687  0.118750\n",
       " 5      0  0.507031  0.376563  0.079687  0.146875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.098437  0.084375  0.021875  0.090625\n",
       " 1      0  0.100000  0.322656  0.028125  0.145313\n",
       " 2      0  0.100781  0.735937  0.039062  0.246875\n",
       " 3      0  0.729688  0.942187  0.090625  0.115625\n",
       " 4      0  0.560938  0.500781  0.093750  0.176563,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.096875  0.900000  0.040625  0.200000\n",
       " 1      0  0.100000  0.428125  0.034375  0.171875\n",
       " 2      0  0.621875  0.651563  0.103125  0.218750\n",
       " 3      0  0.098437  0.142969  0.028125  0.107813,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.103125  0.039062  0.025000  0.078125\n",
       " 1      0  0.100000  0.230469  0.031250  0.126563\n",
       " 2      0  0.097656  0.585156  0.039062  0.220313\n",
       " 3      0  0.534375  0.386719  0.087500  0.164062,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.098437  0.796875  0.040625  0.281250\n",
       " 1      0  0.103906  0.346094  0.032813  0.148438\n",
       " 2      0  0.109375  0.108594  0.025000  0.098437\n",
       " 3      0  0.596094  0.540625  0.098437  0.203125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.428906  0.101562  0.051562  0.090625\n",
       " 1      0  0.117969  0.034375  0.023438  0.068750\n",
       " 2      0  0.114063  0.200781  0.028125  0.114063\n",
       " 3      0  0.102344  0.949219  0.042188  0.101562\n",
       " 4      0  0.670313  0.734375  0.128125  0.237500\n",
       " 5      0  0.107031  0.491406  0.032813  0.176563,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.567969  0.460156  0.089063  0.157813\n",
       " 1      0  0.461719  0.189063  0.057813  0.103125\n",
       " 2      0  0.123438  0.101562  0.021875  0.084375\n",
       " 3      0  0.109375  0.668750  0.040625  0.228125\n",
       " 4      0  0.119531  0.303125  0.032813  0.134375\n",
       " 5      0  0.741406  0.910937  0.110937  0.178125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.128125  0.032031  0.021875  0.064062\n",
       " 1      0  0.110937  0.871094  0.046875  0.257812\n",
       " 2      0  0.493750  0.279687  0.062500  0.118750\n",
       " 3      0  0.421875  0.091406  0.046875  0.089063\n",
       " 4      0  0.122656  0.425781  0.032813  0.154687\n",
       " 5      0  0.128125  0.184375  0.025000  0.096875\n",
       " 6      0  0.625000  0.617969  0.100000  0.198437,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.117188  0.989844  0.043750  0.020313\n",
       " 1      0  0.534375  0.381250  0.081250  0.137500\n",
       " 2      0  0.132031  0.074219  0.020313  0.095312\n",
       " 3      0  0.125781  0.563281  0.035937  0.195312\n",
       " 4      0  0.447656  0.160156  0.051562  0.095312\n",
       " 5      0  0.698438  0.809375  0.131250  0.240625\n",
       " 6      0  0.131250  0.266406  0.028125  0.110937,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.578906  0.500781  0.085938  0.164062\n",
       " 1      0  0.125000  0.728906  0.040625  0.245312\n",
       " 2      0  0.133594  0.135156  0.023438  0.101562\n",
       " 3      0  0.475000  0.232812  0.059375  0.112500\n",
       " 4      0  0.758594  0.942969  0.098437  0.114063\n",
       " 5      0  0.133594  0.357031  0.029687  0.129688,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.505469  0.307031  0.064062  0.120312\n",
       " 1      0  0.125781  0.886719  0.039062  0.226562\n",
       " 2      0  0.133594  0.456250  0.029687  0.153125\n",
       " 3      0  0.134375  0.192188  0.025000  0.115625\n",
       " 4      0  0.636719  0.635938  0.110937  0.209375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.542969  0.389844  0.079687  0.151562\n",
       " 1      0  0.711719  0.805469  0.142188  0.248437\n",
       " 2      0  0.454688  0.139062  0.053125  0.112500\n",
       " 3      0  0.128125  0.046094  0.021875  0.092188\n",
       " 4      0  0.134375  0.575781  0.037500  0.192188\n",
       " 5      0  0.135156  0.260938  0.026562  0.128125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.127344  0.086719  0.023438  0.104687\n",
       " 1      0  0.583594  0.487500  0.085938  0.178125\n",
       " 2      0  0.753906  0.920313  0.101562  0.156250\n",
       " 3      0  0.481250  0.193750  0.059375  0.115625\n",
       " 4      0  0.133594  0.718750  0.039062  0.237500\n",
       " 5      0  0.135156  0.332812  0.029687  0.150000,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.430469  0.033594  0.045312  0.067187\n",
       " 1      0  0.126563  0.135156  0.025000  0.114063\n",
       " 2      0  0.510938  0.256250  0.071875  0.140625\n",
       " 3      0  0.134375  0.871094  0.043750  0.257812\n",
       " 4      0  0.134375  0.419531  0.031250  0.170312\n",
       " 5      0  0.635156  0.605469  0.101562  0.207813,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.450781  0.064062  0.051562  0.109375\n",
       " 1      0  0.014844  0.192188  0.026562  0.096875\n",
       " 2      0  0.125781  0.193750  0.026562  0.131250\n",
       " 3      0  0.694531  0.755469  0.126563  0.232812\n",
       " 4      0  0.138281  0.967969  0.039062  0.064062\n",
       " 5      0  0.133594  0.528906  0.035937  0.198437,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.117188  0.032813  0.025000  0.065625\n",
       " 1      0  0.009375  0.268750  0.018750  0.106250\n",
       " 2      0  0.474219  0.117188  0.057813  0.118750\n",
       " 3      0  0.133594  0.662500  0.035937  0.240625\n",
       " 4      0  0.125781  0.268750  0.029687  0.140625,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.789062  0.990625  0.040625  0.018750\n",
       " 1      0  0.500781  0.188281  0.067187  0.132812\n",
       " 2      0  0.134375  0.828906  0.046875  0.301562\n",
       " 3      0  0.125781  0.357031  0.032813  0.167187\n",
       " 4      0  0.116406  0.065625  0.026562  0.109375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.531250  0.268750  0.081250  0.159375\n",
       " 1      0  0.679688  0.686719  0.121875  0.239063\n",
       " 2      0  0.133594  0.926562  0.039062  0.146875\n",
       " 3      0  0.125781  0.467187  0.035937  0.187500\n",
       " 4      0  0.117969  0.137500  0.026562  0.118750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.117969  0.025781  0.023438  0.051562\n",
       " 1      0  0.128125  0.603906  0.037500  0.220313\n",
       " 2      0  0.121094  0.224219  0.029687  0.135937,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.132031  0.770312  0.045312  0.268750\n",
       " 1      0  0.122656  0.065625  0.029687  0.131250\n",
       " 2      0  0.124219  0.325781  0.032813  0.154687\n",
       " 3      0  0.785937  0.955469  0.081250  0.089063,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.127344  0.458594  0.032813  0.173438\n",
       " 1      0  0.666406  0.663281  0.114063  0.232812,\n",
       "    class         x         y         w        h\n",
       " 0      0  0.735156  0.843750  0.157813  0.26250\n",
       " 1      0  0.130469  0.601562  0.035937  0.20625,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.133594  0.776563  0.042188  0.256250\n",
       " 1      0  0.777344  0.957812  0.082812  0.084375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.101562  0.064844  0.040625  0.067187\n",
       " 1      0  0.664062  0.728125  0.081250  0.118750\n",
       " 2      0  0.142969  0.405469  0.042188  0.335938\n",
       " 3      0  0.134375  0.914062  0.037500  0.171875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.098437  0.120312  0.043750  0.071875\n",
       " 1      0  0.746875  0.943750  0.075000  0.106250\n",
       " 2      0  0.014844  0.120312  0.026562  0.071875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.132812  0.026562  0.021875  0.053125\n",
       " 1      0  0.094531  0.175000  0.045312  0.075000\n",
       " 2      0  0.008594  0.171094  0.017188  0.073438,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.141406  0.139844  0.045312  0.073438\n",
       " 1      0  0.125781  0.044531  0.023438  0.082812\n",
       " 2      0  0.421094  0.221875  0.067187  0.090625\n",
       " 3      0  0.085938  0.224219  0.053125  0.089063,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.371094  0.198437  0.057813  0.087500\n",
       " 1      0  0.028125  0.195312  0.056250  0.096875\n",
       " 2      0  0.254687  0.190625  0.056250  0.090625\n",
       " 3      0  0.449219  0.289844  0.082812  0.101562\n",
       " 4      0  0.121875  0.079687  0.025000  0.090625\n",
       " 5      0  0.139062  0.196094  0.053125  0.082812\n",
       " 6      0  0.202344  0.289844  0.060937  0.101562\n",
       " 7      0  0.075781  0.291406  0.064062  0.107813\n",
       " 8      0  0.328125  0.288281  0.065625  0.098437,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.522656  0.266406  0.079687  0.101562\n",
       " 1      0  0.264062  0.261719  0.062500  0.095312\n",
       " 2      0  0.020313  0.262500  0.040625  0.100000\n",
       " 3      0  0.115625  0.124219  0.025000  0.110937\n",
       " 4      0  0.135937  0.259375  0.059375  0.100000\n",
       " 5      0  0.064062  0.375000  0.068750  0.118750\n",
       " 6      0  0.207031  0.375781  0.067187  0.117188\n",
       " 7      0  0.482812  0.374219  0.103125  0.120312\n",
       " 8      0  0.349219  0.374219  0.085938  0.123438\n",
       " 9      0  0.393750  0.264062  0.078125  0.103125,\n",
       "     class         x         y         w         h\n",
       " 0       0  0.562500  0.344531  0.100000  0.123438\n",
       " 1       0  0.425781  0.071875  0.051562  0.112500\n",
       " 2       0  0.111719  0.178125  0.029687  0.125000\n",
       " 3       0  0.053125  0.479688  0.075000  0.137500\n",
       " 4       0  0.520312  0.477344  0.106250  0.142188\n",
       " 5       0  0.014844  0.345313  0.029687  0.115625\n",
       " 6       0  0.371094  0.475000  0.095312  0.131250\n",
       " 7       0  0.213281  0.479688  0.079687  0.137500\n",
       " 8       0  0.279687  0.340625  0.078125  0.112500\n",
       " 9       0  0.134375  0.341406  0.075000  0.117188\n",
       " 10      0  0.422656  0.345313  0.095312  0.121875,\n",
       "     class         x         y         w         h\n",
       " 0       0  0.007031  0.434375  0.014063  0.109375\n",
       " 1       0  0.100781  0.030469  0.026562  0.060937\n",
       " 2       0  0.450000  0.123438  0.062500  0.125000\n",
       " 3       0  0.041406  0.622656  0.079687  0.182812\n",
       " 4       0  0.614062  0.452344  0.106250  0.135937\n",
       " 5       0  0.575000  0.616406  0.121875  0.173438\n",
       " 6       0  0.223438  0.617188  0.087500  0.175000\n",
       " 7       0  0.133594  0.450000  0.079687  0.140625\n",
       " 8       0  0.109375  0.255469  0.031250  0.139062\n",
       " 9       0  0.295312  0.447656  0.084375  0.139062\n",
       " 10      0  0.454688  0.450000  0.100000  0.143750\n",
       " 11      0  0.402344  0.614062  0.101562  0.171875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.442969  0.808594  0.117188  0.220313\n",
       " 1      0  0.134375  0.599219  0.081250  0.176563\n",
       " 2      0  0.235156  0.811719  0.104687  0.223438\n",
       " 3      0  0.317969  0.594531  0.092188  0.170312\n",
       " 4      0  0.100781  0.077344  0.029687  0.120312\n",
       " 5      0  0.496094  0.600000  0.110937  0.178125\n",
       " 6      0  0.109375  0.364062  0.028125  0.153125\n",
       " 7      0  0.486719  0.210156  0.076563  0.142188,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.346875  0.794531  0.115625  0.207813\n",
       " 1      0  0.555469  0.795313  0.129688  0.212500\n",
       " 2      0  0.429688  0.057031  0.062500  0.114063\n",
       " 3      0  0.696875  0.957812  0.153125  0.081250\n",
       " 4      0  0.254687  0.960938  0.125000  0.071875\n",
       " 5      0  0.486719  0.958594  0.126563  0.082812\n",
       " 6      0  0.111719  0.502344  0.035937  0.189063\n",
       " 7      0  0.103906  0.168750  0.029687  0.137500\n",
       " 8      0  0.524219  0.317187  0.085938  0.165625,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.103125  0.042188  0.025000  0.084375\n",
       " 1      0  0.380469  0.957031  0.129688  0.079687\n",
       " 2      0  0.460938  0.149219  0.062500  0.117188\n",
       " 3      0  0.599219  0.955469  0.151562  0.082812\n",
       " 4      0  0.115625  0.682813  0.040625  0.231250\n",
       " 5      0  0.110156  0.283594  0.029687  0.148438\n",
       " 6      0  0.569531  0.455469  0.092188  0.182812,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.111719  0.137500  0.026562  0.106250\n",
       " 1      0  0.121094  0.883594  0.042188  0.232812\n",
       " 2      0  0.117188  0.418750  0.034375  0.175000\n",
       " 3      0  0.625000  0.622656  0.103125  0.229687\n",
       " 4      0  0.494531  0.259375  0.070312  0.137500,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.119531  0.253125  0.026562  0.118750\n",
       " 1      0  0.121875  0.592969  0.037500  0.217187\n",
       " 2      0  0.539844  0.397656  0.085938  0.164062,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.125000  0.149219  0.021875  0.085938\n",
       " 1      0  0.125781  0.014063  0.023438  0.025000\n",
       " 2      0  0.760938  0.988281  0.043750  0.023438\n",
       " 3      0  0.124219  0.383594  0.029687  0.135937\n",
       " 4      0  0.123438  0.820312  0.043750  0.278125\n",
       " 5      0  0.600000  0.564844  0.093750  0.192188,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.129688  0.067969  0.018750  0.070312\n",
       " 1      0  0.125000  0.525781  0.034375  0.167187\n",
       " 2      0  0.121875  0.954687  0.040625  0.087500\n",
       " 3      0  0.128906  0.239063  0.026562  0.100000\n",
       " 4      0  0.671875  0.750000  0.112500  0.231250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.567969  0.500000  0.079687  0.153125\n",
       " 1      0  0.015625  0.401563  0.028125  0.087500\n",
       " 2      0  0.467187  0.238281  0.050000  0.095312\n",
       " 3      0  0.016406  0.035937  0.032813  0.068750\n",
       " 4      0  0.743750  0.924219  0.103125  0.151562\n",
       " 5      0  0.126563  0.708594  0.040625  0.210938\n",
       " 6      0  0.135156  0.142969  0.020313  0.079687\n",
       " 7      0  0.132812  0.348437  0.028125  0.118750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.631250  0.663281  0.103125  0.204688\n",
       " 1      0  0.128906  0.900781  0.039062  0.198437\n",
       " 2      0  0.141406  0.071875  0.017188  0.062500\n",
       " 3      0  0.428906  0.137500  0.048438  0.087500\n",
       " 4      0  0.503906  0.335156  0.060937  0.120312\n",
       " 5      0  0.013281  0.096094  0.026562  0.076563\n",
       " 6      0  0.011719  0.544531  0.023438  0.110937\n",
       " 7      0  0.135156  0.470313  0.032813  0.143750\n",
       " 8      0  0.139844  0.223438  0.023438  0.087500,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.145313  0.132031  0.018750  0.067187\n",
       " 1      0  0.547656  0.448438  0.070312  0.140625\n",
       " 2      0  0.457031  0.213281  0.054688  0.101562\n",
       " 3      0  0.136719  0.625781  0.032813  0.182812\n",
       " 4      0  0.143750  0.311719  0.025000  0.104687,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.425781  0.128125  0.042188  0.075000\n",
       " 1      0  0.139062  0.855469  0.040625  0.254687\n",
       " 2      0  0.493750  0.303125  0.059375  0.115625\n",
       " 3      0  0.024219  0.668750  0.042188  0.118750\n",
       " 4      0  0.614844  0.608594  0.092188  0.179688\n",
       " 5      0  0.147656  0.208594  0.023438  0.085938\n",
       " 6      0  0.146875  0.428906  0.031250  0.135937,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.709375  0.825781  0.118750  0.232812\n",
       " 1      0  0.012500  0.903125  0.025000  0.146875\n",
       " 2      0  0.453125  0.191406  0.053125  0.095312\n",
       " 3      0  0.148438  0.116406  0.021875  0.070312\n",
       " 4      0  0.146875  0.581250  0.034375  0.178125\n",
       " 5      0  0.147656  0.293750  0.026562  0.106250\n",
       " 6      0  0.542188  0.412500  0.081250  0.140625,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.774219  0.969531  0.079687  0.060937\n",
       " 1      0  0.147656  0.176563  0.020313  0.084375\n",
       " 2      0  0.484375  0.264844  0.062500  0.107813\n",
       " 3      0  0.144531  0.769531  0.039062  0.242188\n",
       " 4      0  0.147656  0.386719  0.029687  0.126563\n",
       " 5      0  0.596875  0.544531  0.093750  0.182812,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.441406  0.152344  0.048438  0.085938\n",
       " 1      0  0.842188  0.589063  0.096875  0.140625\n",
       " 2      0  0.522656  0.360938  0.070312  0.134375\n",
       " 3      0  0.668750  0.725000  0.118750  0.240625\n",
       " 4      0  0.142188  0.935156  0.037500  0.129688\n",
       " 5      0  0.147656  0.249219  0.023438  0.095312\n",
       " 6      0  0.146094  0.514844  0.032813  0.160938,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.892187  0.639063  0.121875  0.118750\n",
       " 1      0  0.147656  0.026562  0.020313  0.053125\n",
       " 2      0  0.749219  0.905469  0.110937  0.189063\n",
       " 3      0  0.471094  0.222656  0.051562  0.101562\n",
       " 4      0  0.146094  0.337500  0.026562  0.115625\n",
       " 5      0  0.146875  0.146094  0.021875  0.073438\n",
       " 6      0  0.571094  0.478125  0.089063  0.162500\n",
       " 7      0  0.145313  0.681250  0.037500  0.209375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.148438  0.074219  0.018750  0.070312\n",
       " 1      0  0.434375  0.130469  0.043750  0.079687\n",
       " 2      0  0.975781  0.853906  0.048438  0.160938\n",
       " 3      0  0.507812  0.314063  0.065625  0.118750\n",
       " 4      0  0.146094  0.886719  0.042188  0.226562\n",
       " 5      0  0.147656  0.217187  0.023438  0.090625\n",
       " 6      0  0.148438  0.457031  0.031250  0.139062\n",
       " 7      0  0.639063  0.641406  0.109375  0.214062,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.722656  0.853125  0.129688  0.259375\n",
       " 1      0  0.460156  0.200781  0.051562  0.092188\n",
       " 2      0  0.552344  0.428125  0.079687  0.140625\n",
       " 3      0  0.147656  0.135156  0.020313  0.079687\n",
       " 4      0  0.146875  0.307813  0.025000  0.109375\n",
       " 5      0  0.146875  0.609375  0.034375  0.178125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.146875  0.200781  0.021875  0.092188\n",
       " 1      0  0.145313  0.818750  0.040625  0.243750\n",
       " 2      0  0.146875  0.413281  0.028125  0.126563\n",
       " 3      0  0.610156  0.572656  0.098437  0.176563\n",
       " 4      0  0.492188  0.283594  0.059375  0.107813,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.448438  0.188281  0.046875  0.082812\n",
       " 1      0  0.141406  0.971094  0.039062  0.057813\n",
       " 2      0  0.145313  0.287500  0.025000  0.109375\n",
       " 3      0  0.145313  0.553906  0.034375  0.167187\n",
       " 4      0  0.533594  0.386719  0.076563  0.132812\n",
       " 5      0  0.689062  0.770312  0.125000  0.225000,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.480469  0.270312  0.057813  0.100000\n",
       " 1      0  0.142969  0.741406  0.039062  0.220313\n",
       " 2      0  0.760156  0.941406  0.098437  0.117188\n",
       " 3      0  0.585938  0.523438  0.090625  0.168750\n",
       " 4      0  0.145313  0.390625  0.028125  0.131250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.446094  0.191406  0.045312  0.082812\n",
       " 1      0  0.158594  0.115625  0.026562  0.068750\n",
       " 2      0  0.142969  0.541406  0.032813  0.170312\n",
       " 3      0  0.141406  0.941406  0.035937  0.110937\n",
       " 4      0  0.521094  0.385156  0.070312  0.120312\n",
       " 5      0  0.665625  0.725781  0.109375  0.220313,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.412500  0.019531  0.018750  0.032813\n",
       " 1      0  0.424219  0.110937  0.023438  0.059375\n",
       " 2      0  0.143750  0.385156  0.025000  0.114063\n",
       " 3      0  0.476562  0.275000  0.056250  0.100000\n",
       " 4      0  0.744531  0.916406  0.107813  0.167187\n",
       " 5      0  0.159375  0.182031  0.028125  0.079687\n",
       " 6      0  0.571094  0.514844  0.089063  0.157813\n",
       " 7      0  0.141406  0.729688  0.039062  0.234375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.014844  0.504687  0.029687  0.103125\n",
       " 1      0  0.448438  0.171094  0.034375  0.073438\n",
       " 2      0  0.141406  0.512500  0.032813  0.140625\n",
       " 3      0  0.137500  0.914844  0.037500  0.170312\n",
       " 4      0  0.510938  0.372656  0.068750  0.120312\n",
       " 5      0  0.157031  0.258594  0.032813  0.101562\n",
       " 6      0  0.642969  0.691406  0.107813  0.210938,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.135156  0.688281  0.032813  0.179688\n",
       " 1      0  0.450000  0.105469  0.018750  0.057813\n",
       " 2      0  0.179688  0.159375  0.031250  0.081250\n",
       " 3      0  0.475781  0.242969  0.042188  0.092188\n",
       " 4      0  0.559375  0.495313  0.084375  0.156250\n",
       " 5      0  0.155469  0.349219  0.035937  0.120312,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.458594  0.043750  0.017188  0.056250\n",
       " 1      0  0.471094  0.158594  0.023438  0.067187\n",
       " 2      0  0.176563  0.225000  0.034375  0.093750\n",
       " 3      0  0.504687  0.329688  0.053125  0.106250\n",
       " 4      0  0.149219  0.467187  0.035937  0.153125\n",
       " 5      0  0.621875  0.663281  0.103125  0.207813,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.205469  0.139844  0.032813  0.076563\n",
       " 1      0  0.492969  0.229687  0.029687  0.081250\n",
       " 2      0  0.136719  0.642969  0.045312  0.210938\n",
       " 3      0  0.546094  0.453125  0.064062  0.137500\n",
       " 4      0  0.166406  0.318750  0.042188  0.112500,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.227344  0.071094  0.026562  0.057813\n",
       " 1      0  0.121094  0.865625  0.048438  0.268750\n",
       " 2      0  0.483594  0.141406  0.023438  0.070312\n",
       " 3      0  0.515625  0.315625  0.040625  0.103125\n",
       " 4      0  0.151562  0.429688  0.040625  0.137500\n",
       " 5      0  0.192188  0.210156  0.040625  0.092188\n",
       " 6      0  0.594531  0.606250  0.085938  0.175000,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.209375  0.125000  0.031250  0.065625\n",
       " 1      0  0.664844  0.822656  0.114063  0.239063\n",
       " 2      0  0.492188  0.207813  0.031250  0.084375\n",
       " 3      0  0.542188  0.425000  0.053125  0.125000\n",
       " 4      0  0.172656  0.291406  0.042188  0.107813\n",
       " 5      0  0.127344  0.581250  0.045312  0.181250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.212500  0.054688  0.021875  0.068750\n",
       " 1      0  0.706250  0.982813  0.056250  0.034375\n",
       " 2      0  0.466406  0.122656  0.026562  0.064062\n",
       " 3      0  0.097656  0.800781  0.051562  0.257812\n",
       " 4      0  0.502344  0.288281  0.045312  0.107813\n",
       " 5      0  0.182812  0.189063  0.034375  0.078125\n",
       " 6      0  0.575000  0.570312  0.071875  0.168750\n",
       " 7      0  0.145313  0.398438  0.050000  0.134375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.181250  0.100781  0.021875  0.079687\n",
       " 1      0  0.460156  0.178125  0.035937  0.084375\n",
       " 2      0  0.060156  0.964844  0.045312  0.070312\n",
       " 3      0  0.622656  0.775000  0.101562  0.240625\n",
       " 4      0  0.151562  0.265625  0.037500  0.100000\n",
       " 5      0  0.110937  0.539844  0.056250  0.173438\n",
       " 6      0  0.517187  0.391406  0.059375  0.132812,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.459375  0.252344  0.046875  0.101562\n",
       " 1      0  0.667188  0.950781  0.078125  0.098437\n",
       " 2      0  0.146094  0.163281  0.029687  0.089063\n",
       " 3      0  0.114844  0.367188  0.045312  0.118750\n",
       " 4      0  0.065625  0.742188  0.062500  0.237500\n",
       " 5      0  0.539062  0.526563  0.081250  0.168750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.578125  0.723437  0.109375  0.243750\n",
       " 1      0  0.113281  0.238281  0.032813  0.104687\n",
       " 2      0  0.025781  0.930469  0.051562  0.139062\n",
       " 3      0  0.075000  0.502344  0.053125  0.154687\n",
       " 4      0  0.470313  0.350000  0.053125  0.121875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.079687  0.129688  0.025000  0.081250\n",
       " 1      0  0.628906  0.917188  0.092188  0.165625\n",
       " 2      0  0.083594  0.334375  0.035937  0.131250\n",
       " 3      0  0.038281  0.690625  0.064062  0.209375\n",
       " 4      0  0.495313  0.478906  0.075000  0.157813,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.062500  0.203906  0.028125  0.089063\n",
       " 1      0  0.039844  0.065625  0.026562  0.062500\n",
       " 2      0  0.018750  0.907812  0.037500  0.184375\n",
       " 3      0  0.063281  0.466406  0.045312  0.167187\n",
       " 4      0  0.546094  0.666406  0.092188  0.214062,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.010937  0.021875  0.018750  0.040625\n",
       " 1      0  0.049219  0.299219  0.029687  0.114063\n",
       " 2      0  0.618750  0.885938  0.112500  0.228125\n",
       " 3      0  0.028906  0.125781  0.026562  0.064062\n",
       " 4      0  0.465625  0.423438  0.084375  0.156250\n",
       " 5      0  0.046094  0.642969  0.054688  0.223438,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.010937  0.069531  0.018750  0.057813\n",
       " 1      0  0.045312  0.417969  0.034375  0.139062\n",
       " 2      0  0.026562  0.200000  0.028125  0.081250\n",
       " 3      0  0.034375  0.869531  0.059375  0.260938\n",
       " 4      0  0.525000  0.583594  0.096875  0.198437,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.007812  0.021875  0.015625  0.043750\n",
       " 1      0  0.047656  0.574219  0.039062  0.189063\n",
       " 2      0  0.017969  0.125781  0.023438  0.064062\n",
       " 3      0  0.617969  0.800000  0.132812  0.253125\n",
       " 4      0  0.032031  0.289062  0.029687  0.093750,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.023438  0.066406  0.018750  0.064062\n",
       " 1      0  0.696875  0.961719  0.081250  0.076563\n",
       " 2      0  0.044531  0.400000  0.029687  0.118750\n",
       " 3      0  0.032813  0.195312  0.025000  0.078125\n",
       " 4      0  0.511719  0.528906  0.101562  0.167187,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.443750  0.378906  0.078125  0.123438\n",
       " 1      0  0.352344  0.190625  0.051562  0.090625\n",
       " 2      0  0.037500  0.021094  0.021875  0.035937\n",
       " 3      0  0.064062  0.948438  0.037500  0.103125\n",
       " 4      0  0.596875  0.725781  0.115625  0.235938\n",
       " 5      0  0.050781  0.277344  0.026562  0.095312\n",
       " 6      0  0.042188  0.122656  0.018750  0.067187\n",
       " 7      0  0.059375  0.542969  0.034375  0.154687,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.786719  0.593750  0.082812  0.103125\n",
       " 1      0  0.326562  0.098437  0.046875  0.081250\n",
       " 2      0  0.062500  0.184375  0.021875  0.078125\n",
       " 3      0  0.400781  0.265625  0.060937  0.106250\n",
       " 4      0  0.693750  0.916406  0.109375  0.167187\n",
       " 5      0  0.072656  0.730469  0.039062  0.195312\n",
       " 6      0  0.067969  0.379687  0.026562  0.112500\n",
       " 7      0  0.514844  0.510938  0.098437  0.159375,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.078125  0.013281  0.021875  0.023438\n",
       " 1      0  0.464063  0.371875  0.075000  0.128125\n",
       " 2      0  0.854688  0.660937  0.143750  0.125000\n",
       " 3      0  0.375000  0.164844  0.053125  0.095312\n",
       " 4      0  0.085156  0.936719  0.039062  0.123438\n",
       " 5      0  0.607813  0.705469  0.118750  0.226562\n",
       " 6      0  0.078125  0.108594  0.018750  0.070312\n",
       " 7      0  0.082031  0.268750  0.023438  0.090625\n",
       " 8      0  0.085156  0.519531  0.032813  0.151562,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.958594  0.875000  0.082812  0.168750\n",
       " 1      0  0.524219  0.489844  0.092188  0.164062\n",
       " 2      0  0.092188  0.160938  0.018750  0.075000\n",
       " 3      0  0.094531  0.678906  0.035937  0.189063\n",
       " 4      0  0.094531  0.357031  0.026562  0.117188\n",
       " 5      0  0.417188  0.230469  0.059375  0.104687,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.103906  0.075781  0.017188  0.060937\n",
       " 1      0  0.389844  0.138281  0.042188  0.073438\n",
       " 2      0  0.099219  0.885938  0.042188  0.228125\n",
       " 3      0  0.103125  0.225000  0.021875  0.087500\n",
       " 4      0  0.102344  0.467187  0.032813  0.143750\n",
       " 5      0  0.464063  0.312500  0.071875  0.125000\n",
       " 6      0  0.594531  0.642187  0.104687  0.212500,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.425000  0.191406  0.046875  0.085938\n",
       " 1      0  0.112500  0.118750  0.018750  0.059375\n",
       " 2      0  0.514063  0.409375  0.078125  0.143750\n",
       " 3      0  0.109375  0.297656  0.025000  0.104687\n",
       " 4      0  0.106250  0.607813  0.034375  0.181250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.741406  0.964063  0.079687  0.071875\n",
       " 1      0  0.115625  0.167969  0.021875  0.070312\n",
       " 2      0  0.459375  0.253906  0.059375  0.101562\n",
       " 3      0  0.106250  0.795313  0.040625  0.243750\n",
       " 4      0  0.112500  0.388281  0.031250  0.126563\n",
       " 5      0  0.570312  0.532031  0.096875  0.182812,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.500000  0.342969  0.065625  0.114063\n",
       " 1      0  0.118750  0.238281  0.021875  0.085938\n",
       " 2      0  0.105469  0.942187  0.045312  0.115625\n",
       " 3      0  0.638281  0.696875  0.126563  0.225000\n",
       " 4      0  0.114063  0.508594  0.034375  0.164062,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.131250  0.121094  0.018750  0.067187\n",
       " 1      0  0.543750  0.453906  0.078125  0.142188\n",
       " 2      0  0.114063  0.665625  0.037500  0.212500\n",
       " 3      0  0.121094  0.318750  0.026562  0.103125,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.465625  0.271094  0.081250  0.132812\n",
       " 1      0  0.132812  0.175781  0.018750  0.070312\n",
       " 2      0  0.114844  0.860156  0.045312  0.279687\n",
       " 3      0  0.122656  0.414844  0.029687  0.120312\n",
       " 4      0  0.598437  0.588281  0.096875  0.176563,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.499219  0.357812  0.095312  0.165625\n",
       " 1      0  0.132812  0.228906  0.021875  0.082812\n",
       " 2      0  0.114063  0.968750  0.040625  0.062500\n",
       " 3      0  0.664844  0.760156  0.123438  0.210938\n",
       " 4      0  0.121094  0.532031  0.032813  0.151562,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.985156  0.032031  0.026562  0.064062\n",
       " 1      0  0.909375  0.709375  0.081250  0.087500\n",
       " 2      0  0.722656  0.909375  0.107813  0.181250\n",
       " 3      0  0.116406  0.671094  0.039062  0.192188\n",
       " 4      0  0.129688  0.296094  0.021875  0.095312,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.126563  0.366406  0.025000  0.110937\n",
       " 1      0  0.112500  0.842188  0.040625  0.246875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.970312  0.852344  0.059375  0.160938\n",
       " 1      0  0.104687  0.945312  0.046875  0.109375\n",
       " 2      0  0.120312  0.444531  0.028125  0.126563,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.425781  0.982031  0.029687  0.035937\n",
       " 1      0  0.112500  0.535156  0.031250  0.154687,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.518750  0.446094  0.068750  0.110937\n",
       " 1      0  0.107031  0.638281  0.032813  0.182812,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.728906  0.971875  0.064062  0.056250\n",
       " 1      0  0.561719  0.547656  0.070312  0.110937\n",
       " 2      0  0.100000  0.767187  0.037500  0.231250,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.606250  0.650781  0.065625  0.107813\n",
       " 1      0  0.096094  0.885156  0.042188  0.229687,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.651563  0.754687  0.068750  0.115625\n",
       " 1      0  0.292188  0.335938  0.031250  0.081250\n",
       " 2      0  0.089063  0.946875  0.040625  0.106250,\n",
       "    class         x         y       w        h\n",
       " 0      0  0.709375  0.893750  0.0750  0.10625\n",
       " 1      0  0.303125  0.382812  0.0375  0.10000,\n",
       "    class         x        y         w         h\n",
       " 0      0  0.319531  0.44375  0.045312  0.121875,\n",
       "    class         x         y         w         h\n",
       " 0      0  0.517187  0.128906  0.081250  0.104687\n",
       " 1      0  0.336719  0.519531  0.048438  0.129688]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.concat(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(dataframe)[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training = dataframe[cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>450.99968</td>\n",
       "      <td>632.00000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>327.00032</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348.49984</td>\n",
       "      <td>177.50016</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>582.49984</td>\n",
       "      <td>50.0</td>\n",
       "      <td>115.00032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394.00000</td>\n",
       "      <td>368.49984</td>\n",
       "      <td>44.0</td>\n",
       "      <td>103.00032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>454.00000</td>\n",
       "      <td>572.00000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>68.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>194.00000</td>\n",
       "      <td>244.99968</td>\n",
       "      <td>24.0</td>\n",
       "      <td>64.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>204.49984</td>\n",
       "      <td>284.00000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>78.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>330.99968</td>\n",
       "      <td>82.49984</td>\n",
       "      <td>52.0</td>\n",
       "      <td>66.99968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>215.50016</td>\n",
       "      <td>332.49984</td>\n",
       "      <td>31.0</td>\n",
       "      <td>83.00032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>861 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x          y     w          h\n",
       "0    450.99968  632.00000  26.0   16.00000\n",
       "1    327.00032   80.00000  20.0   42.00000\n",
       "2    348.49984  177.50016  27.0   59.00000\n",
       "3     50.00000  582.49984  50.0  115.00032\n",
       "4    394.00000  368.49984  44.0  103.00032\n",
       "..         ...        ...   ...        ...\n",
       "856  454.00000  572.00000  48.0   68.00000\n",
       "857  194.00000  244.99968  24.0   64.00000\n",
       "858  204.49984  284.00000  29.0   78.00000\n",
       "859  330.99968   82.49984  52.0   66.99968\n",
       "860  215.50016  332.49984  31.0   83.00032\n",
       "\n",
       "[861 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training * 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training['center_x'] = (df_for_training['x'] + df_for_training['w']) / 2\n",
    "df_for_training['center_y'] = (df_for_training['y'] + df_for_training['h']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.704687</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.372656</td>\n",
       "      <td>0.506250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510938</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.271094</td>\n",
       "      <td>0.095312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.544531</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>0.042188</td>\n",
       "      <td>0.092188</td>\n",
       "      <td>0.293359</td>\n",
       "      <td>0.184766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.544922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.615625</td>\n",
       "      <td>0.575781</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.160938</td>\n",
       "      <td>0.342187</td>\n",
       "      <td>0.368360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.392187</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0.303125</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.170312</td>\n",
       "      <td>0.241406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>0.319531</td>\n",
       "      <td>0.443750</td>\n",
       "      <td>0.045312</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.182422</td>\n",
       "      <td>0.282812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.517187</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.104687</td>\n",
       "      <td>0.299218</td>\n",
       "      <td>0.116796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.336719</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>0.048438</td>\n",
       "      <td>0.129688</td>\n",
       "      <td>0.192578</td>\n",
       "      <td>0.324609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>861 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y         w         h  center_x  center_y\n",
       "0    0.704687  0.987500  0.040625  0.025000  0.372656  0.506250\n",
       "1    0.510938  0.125000  0.031250  0.065625  0.271094  0.095312\n",
       "2    0.544531  0.277344  0.042188  0.092188  0.293359  0.184766\n",
       "3    0.078125  0.910156  0.078125  0.179688  0.078125  0.544922\n",
       "4    0.615625  0.575781  0.068750  0.160938  0.342187  0.368360\n",
       "..        ...       ...       ...       ...       ...       ...\n",
       "856  0.709375  0.893750  0.075000  0.106250  0.392187  0.500000\n",
       "857  0.303125  0.382812  0.037500  0.100000  0.170312  0.241406\n",
       "858  0.319531  0.443750  0.045312  0.121875  0.182422  0.282812\n",
       "859  0.517187  0.128906  0.081250  0.104687  0.299218  0.116796\n",
       "860  0.336719  0.519531  0.048438  0.129688  0.192578  0.324609\n",
       "\n",
       "[861 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_for_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert the center points into a sequence\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sequence \u001b[38;5;241m=\u001b[39m \u001b[43mdf_for_training\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter_y\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Reshape into [samples, time steps, features]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Here, samples = 1, time steps = number of rows, features = 2 (center_x, center_y)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_for_training' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the center points into a sequence\n",
    "sequence = df_for_training[['center_x', 'center_y']].values\n",
    "\n",
    "# Reshape into [samples, time steps, features]\n",
    "# Here, samples = 1, time steps = number of rows, features = 2 (center_x, center_y)\n",
    "X = sequence.reshape(1, sequence.shape[0], sequence.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X.reshape(-1, 2)).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b67545d4e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_normalized.shape[1], X_normalized.shape[2])))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(2))  # Output layer with 2 units for center_x and center_y\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_normalized, X_normalized, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data with the same structure\n",
    "test_data = {\n",
    "    'x1': [460.99968, 310.00032, 350.49984],\n",
    "    'x2': [620.00000, 90.00000, 170.50016],\n",
    "    'y1': [25.0, 22.0, 28.0],\n",
    "    'y2': [17.0, 40.0, 58.0]\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Calculate the center points for the test rectangles\n",
    "test_df['center_x'] = (test_df['x1'] + test_df['x2']) / 2\n",
    "test_df['center_y'] = (test_df['y1'] + test_df['y2']) / 2\n",
    "\n",
    "# Convert the center points into a sequence\n",
    "test_sequence = test_df[['center_x', 'center_y']].values\n",
    "\n",
    "# Reshape into [samples, time steps, features]\n",
    "test_X = test_sequence.reshape(1, test_sequence.shape[0], test_sequence.shape[1])\n",
    "\n",
    "# # Normalize the test data using the same scaler fitted on the training data\n",
    "# test_X_normalized = scaler.transform(test_X.reshape(-1, 2)).reshape(test_X.shape)\n",
    "\n",
    "# Prepare the target data (for evaluation, we can use the same normalized data as targets)\n",
    "test_y = test_X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(test_X_normalized, test_y, verbose=0)\n",
    "\n",
    "print(f\"Test Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Predictions: [[nan nan]]\n",
      "Predictions in original scale: [[nan nan]]\n"
     ]
    }
   ],
   "source": [
    "new_data = {\n",
    "    'x1': [400.99968, 300.00032, 340.49984],\n",
    "    'x2': [600.00000, 100.00000, 180.50016],\n",
    "    'y1': [30.0, 25.0, 30.0],\n",
    "    'y2': [10.0, 35.0, 60.0]\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Calculate the center points for the new rectangles\n",
    "new_df['center_x'] = (new_df['x1'] + new_df['x2']) / 2\n",
    "new_df['center_y'] = (new_df['y1'] + new_df['y2']) / 2\n",
    "\n",
    "# Convert the center points into a sequence\n",
    "new_sequence = new_df[['center_x', 'center_y']].values\n",
    "\n",
    "# Reshape into [samples, time steps, features]\n",
    "new_X = new_sequence.reshape(1, new_sequence.shape[0], new_sequence.shape[1])\n",
    "\n",
    "# Normalize the new data\n",
    "new_X_normalized = scaler.transform(new_X.reshape(-1, 2)).reshape(new_X.shape)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_X_normalized)\n",
    "\n",
    "# Inverse transform the predictions if you want to get them back to the original scale\n",
    "predictions_original_scale = scaler.inverse_transform(predictions)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Predictions in original scale:\", predictions_original_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.704687</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.372656</td>\n",
       "      <td>0.506250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510938</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.271094</td>\n",
       "      <td>0.095312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.544531</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>0.042188</td>\n",
       "      <td>0.092188</td>\n",
       "      <td>0.293359</td>\n",
       "      <td>0.184766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.544922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.615625</td>\n",
       "      <td>0.575781</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.160938</td>\n",
       "      <td>0.342187</td>\n",
       "      <td>0.368360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.392187</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0.303125</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.170312</td>\n",
       "      <td>0.241406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>0.319531</td>\n",
       "      <td>0.443750</td>\n",
       "      <td>0.045312</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.182422</td>\n",
       "      <td>0.282812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.517187</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.104687</td>\n",
       "      <td>0.299218</td>\n",
       "      <td>0.116796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.336719</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>0.048438</td>\n",
       "      <td>0.129688</td>\n",
       "      <td>0.192578</td>\n",
       "      <td>0.324609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>861 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y         w         h  center_x  center_y\n",
       "0    0.704687  0.987500  0.040625  0.025000  0.372656  0.506250\n",
       "1    0.510938  0.125000  0.031250  0.065625  0.271094  0.095312\n",
       "2    0.544531  0.277344  0.042188  0.092188  0.293359  0.184766\n",
       "3    0.078125  0.910156  0.078125  0.179688  0.078125  0.544922\n",
       "4    0.615625  0.575781  0.068750  0.160938  0.342187  0.368360\n",
       "..        ...       ...       ...       ...       ...       ...\n",
       "856  0.709375  0.893750  0.075000  0.106250  0.392187  0.500000\n",
       "857  0.303125  0.382812  0.037500  0.100000  0.170312  0.241406\n",
       "858  0.319531  0.443750  0.045312  0.121875  0.182422  0.282812\n",
       "859  0.517187  0.128906  0.081250  0.104687  0.299218  0.116796\n",
       "860  0.336719  0.519531  0.048438  0.129688  0.192578  0.324609\n",
       "\n",
       "[861 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_for_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdf_for_training\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_for_training' is not defined"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df_for_training, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(len(df_for_training) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_train = df_for_training[:split_point]\n",
    "hp_test = df_for_training[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 Complete [00h 01m 12s]\n",
      "val_loss: 0.08042242377996445\n",
      "\n",
      "Best val_loss So Far: 0.07717413455247879\n",
      "Total elapsed time: 00h 36m 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\D\\SKRIPSI\\env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 24 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'num_layers': 3, 'units_0': 384, 'learning_rate': 0.005280303264814981, 'units_1': 32, 'units_2': 32}\n",
      "Test Loss: 0.07708746939897537\n"
     ]
    }
   ],
   "source": [
    "# # Hypermodel definition\n",
    "# class LSTMHyperModel(tf.keras.Model):\n",
    "#     def build(self, hp):\n",
    "#         model = Sequential()\n",
    "#         model.add(Input(shape=(None, 2)))\n",
    "\n",
    "#         for i in range(hp.Int('num_layers', 1, 3)):\n",
    "#             model.add(LSTM(units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),\n",
    "#                            return_sequences=True if i < hp.Int('num_layers', 1, 3) - 1 else False))\n",
    "        \n",
    "#         model.add(Dense(2))\n",
    "#         model.compile(optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "#                       loss='mse')\n",
    "\n",
    "#         return model\n",
    "\n",
    "# # Tuner definition\n",
    "# tuner = kt.RandomSearch(\n",
    "#     LSTMHyperModel(),\n",
    "#     objective='val_loss',\n",
    "#     max_trials=20,\n",
    "#     executions_per_trial=2,\n",
    "#     directory='my_dir',\n",
    "#     project_name='lstm_tuning'\n",
    "# )\n",
    "\n",
    "class LSTMHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(None, 2)))  \n",
    "\n",
    "        for i in range(hp.Int('num_layers', 1, 3)):\n",
    "            model.add(LSTM(units=hp.Int(f'units_{i}', \n",
    "                                        min_value=32, max_value=512, step=32),\n",
    "                                  return_sequences=True if i < hp.Int('num_layers', \n",
    "                                                                      1, 3) - 1 else False))\n",
    "        model.add(Dense(2))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam\n",
    "                      (hp.Float('learning_rate', min_value=1e-4, \n",
    "                                max_value=1e-2, sampling='LOG')),\n",
    "                      loss='mse')\n",
    "        tf1.reset_default_graph()\n",
    "        return model\n",
    "\n",
    "# Tuner definition\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=LSTMHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=22,  # Number of hyperparameter combinations to try\n",
    "    executions_per_trial=2,  # Number of models to train for each combination\n",
    "    directory='my_dir',  # Directory where the tuner stores results\n",
    "    project_name='lstm_tuning'\n",
    ")\n",
    "\n",
    "# Prepare training data\n",
    "train_sequence = hp_train[['center_x', 'center_y']].values\n",
    "scaler = MinMaxScaler()\n",
    "train_X_normalized = scaler.fit_transform(train_sequence).reshape(1, train_sequence.shape[0], train_sequence.shape[1])\n",
    "\n",
    "# Prepare test data\n",
    "test_sequence = hp_test[['center_x', 'center_y']].values\n",
    "test_X_normalized = scaler.transform(test_sequence).reshape(1, test_sequence.shape[0], test_sequence.shape[1])\n",
    "\n",
    "train_y = train_X_normalized\n",
    "test_y = test_X_normalized\n",
    "\n",
    "# Hyperparameter search\n",
    "tuner.search(train_X_normalized, train_y, validation_data=(test_X_normalized, test_y), epochs=100, batch_size=32)\n",
    "\n",
    "# Get best model and hyperparameters\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# Evaluate the best model\n",
    "test_loss = best_model.evaluate(test_X_normalized, test_y, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = hp_train[['center_x', 'center_y']].values\n",
    "scaler = MinMaxScaler()\n",
    "train_X_normalized = scaler.fit_transform(train_sequence).reshape(1, train_sequence.shape[0], train_sequence.shape[1])\n",
    "\n",
    "# Prepare test data\n",
    "test_sequence = hp_test[['center_x', 'center_y']].values\n",
    "test_X_normalized = scaler.transform(test_sequence).reshape(1, test_sequence.shape[0], test_sequence.shape[1])\n",
    "\n",
    "train_y = train_X_normalized\n",
    "test_y = test_X_normalized\n",
    "\n",
    "# # Hyperparameter search\n",
    "# tuner.search(train_X_normalized, train_y, validation_data=(test_X_normalized, test_y), epochs=100, batch_size=32)\n",
    "\n",
    "# # Get best model and hyperparameters\n",
    "# best_model = tuner.get_best_models(num_models=1)[0]\n",
    "# best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372656</td>\n",
       "      <td>0.506250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.271094</td>\n",
       "      <td>0.095312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.293359</td>\n",
       "      <td>0.184766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.544922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.342187</td>\n",
       "      <td>0.368360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0.321875</td>\n",
       "      <td>0.325782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.095703</td>\n",
       "      <td>0.234766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0.237891</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.247266</td>\n",
       "      <td>0.112891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.105469</td>\n",
       "      <td>0.159375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     center_x  center_y\n",
       "0    0.372656  0.506250\n",
       "1    0.271094  0.095312\n",
       "2    0.293359  0.184766\n",
       "3    0.078125  0.544922\n",
       "4    0.342187  0.368360\n",
       "..        ...       ...\n",
       "683  0.321875  0.325782\n",
       "684  0.095703  0.234766\n",
       "685  0.237891  0.050000\n",
       "686  0.247266  0.112891\n",
       "687  0.105469  0.159375\n",
       "\n",
       "[688 rows x 2 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_sequence, columns=[\"center_x\", \"center_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = train_df[['mid_x', 'mid_y']].values\n",
    "scaler = MinMaxScaler()\n",
    "train_X_normalized = scaler.fit_transform(train_sequence).reshape(1, train_sequence.shape[0], train_sequence.shape[1])\n",
    "\n",
    "# Prepare test data\n",
    "test_sequence = test_df[['mid_x', 'mid_y']].values\n",
    "test_X_normalized = scaler.transform(test_sequence).reshape(1, test_sequence.shape[0], test_sequence.shape[1])\n",
    "\n",
    "train_y = train_X_normalized\n",
    "test_y = test_X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Hyperparameter search\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241m.\u001b[39msearch(train_X_normalized, train_y, validation_data\u001b[38;5;241m=\u001b[39m(test_X_normalized, test_y), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get best model and hyperparameters\u001b[39;00m\n\u001b[0;32m      5\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tuner' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparameter search\n",
    "tuner.search(train_X_normalized, train_y, validation_data=(test_X_normalized, test_y), epochs=50, batch_size=32)\n",
    "\n",
    "# Get best model and hyperparameters\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# Evaluate the best model\n",
    "test_loss = best_model.evaluate(test_X_normalized, test_y, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_linepred.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.save('best_linepred.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\D\\SKRIPSI\\env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your saved model file\n",
    "model_path = 'best_linepred.keras'  # Replace with your actual path\n",
    "\n",
    "# Load the model architecture and weights\n",
    "loaded_model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=True>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.704687 0.9875 0.040625 0.025\n",
    "0.510938 0.125 0.03125 0.065625\n",
    "0.544531 0.277344 0.0421875 0.0921875\n",
    "0.078125 0.910156 0.078125 0.179688\n",
    "0.615625 0.575781 0.06875 0.160938\n",
    "0.167187 0.470313 0.053125 0.134375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your new data (ensure same format as training data)\n",
    "# data = {\n",
    "    # 'x1': [450.99968, 327.00032, 348.49984],\n",
    "    # 'x2': [632.00000, 80.00000, 177.50016],\n",
    "    # 'y1': [26.0, 20.0, 27.0],\n",
    "    # 'y2': [16.0, 42.0, 59.0]\n",
    "# }\n",
    "# 0 0.721094 0.924219 0.101562 0.151562\n",
    "# 0 0.549219 0.466406 0.0796875 0.154687\n",
    "yolo_detection = {\n",
    "    'x': [0.721094,\n",
    "          0.549219],\n",
    "    'y': [0.924219,\n",
    "          .466406],\n",
    "    'w': [0.101562,\n",
    "          0.0796875 ],\n",
    "    'h': [0.151562,\n",
    "          0.154687]\n",
    "}\n",
    "\n",
    "# 0.615625 0.575781 0.06875 0.160938\n",
    "# Make predictions on the new data\n",
    "# predictions = loaded_model.predict(yolo_detection)\n",
    "\n",
    "# print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(yolo_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461.50016</td>\n",
       "      <td>591.50016</td>\n",
       "      <td>64.99968</td>\n",
       "      <td>96.99968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>351.50016</td>\n",
       "      <td>298.49984</td>\n",
       "      <td>51.00000</td>\n",
       "      <td>98.99968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y         w         h\n",
       "0  461.50016  591.50016  64.99968  96.99968\n",
       "1  351.50016  298.49984  51.00000  98.99968"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred*640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['center_x'] = (df_pred['x'] + df_pred['w']) / 2\n",
    "df_pred['center_y'] = (df_pred['y'] + df_pred['h']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.721094</td>\n",
       "      <td>0.924219</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.151562</td>\n",
       "      <td>0.411328</td>\n",
       "      <td>0.537891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.549219</td>\n",
       "      <td>0.466406</td>\n",
       "      <td>0.079687</td>\n",
       "      <td>0.154687</td>\n",
       "      <td>0.314453</td>\n",
       "      <td>0.310547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         w         h  center_x  center_y\n",
       "0  0.721094  0.924219  0.101562  0.151562  0.411328  0.537891\n",
       "1  0.549219  0.466406  0.079687  0.154687  0.314453  0.310547"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.372656, 0.50625 ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sequence[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sequence = df_pred[['center_x', 'center_y']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.411328  , 0.5378905 ],\n",
       "       [0.31445325, 0.3105465 ]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sequence = df_pred[['center_x', 'center_y']].values\n",
    "# pred_X_normalizeds = scaler.transform(pred_sequence[[0]]).reshape(1, pred_sequence[[0]].shape[0], pred_sequence[[0]].shape[1])\n",
    "pred_X= scaler.transform(train_sequence).reshape(1, train_sequence.shape[0], train_sequence.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.6897315 , 0.88936454],\n",
       "        [0.49628012, 0.13847249],\n",
       "        [0.53869011, 0.30192735],\n",
       "        ...,\n",
       "        [0.43303585, 0.05567451],\n",
       "        [0.45089299, 0.17059262],\n",
       "        [0.180804  , 0.2555317 ]]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res():\n",
    "    result = []\n",
    "    for i in range (0,5):\n",
    "        # pred_X = pred_sequence[[i]].reshape(1, pred_sequence[[i]].shape[0], pred_sequence[[i]].shape[1])\n",
    "        predictions = loaded_model.predict(pred_X[0][i])\n",
    "        print(predictions)\n",
    "        result.append(predictions)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(pred_X)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(pred_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_pred\u001b[49m\u001b[38;5;241m.\u001b[39mh[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_pred' is not defined"
     ]
    }
   ],
   "source": [
    "df_pred.h[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05856669, 0.10003754]], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.array([[301/640,134/640]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.209375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "# Assuming you have an image (loaded using OpenCV) and bounding box information\n",
    "image = cv2.imread('C:\\\\D\\\\SKRIPSI\\\\yolov5\\\\runs\\\\detect\\\\inference_10\\\\images\\\\frame00211.png')  # Replace with your image loading method\n",
    "# x1, y1, x2, y2 = pred_x1,pred_y1, pred_x2, pred_y2 # Replace with your bounding box coordinates\n",
    "x, y, w, h =  prediction[0][0],prediction[0][1],50/640,97/640# Replace with your bounding box coordinates\n",
    "# # Calculate width and height (if not provided)\n",
    "# width = x2 - x1\n",
    "# height = y2 - y1\n",
    "\n",
    "# # Draw the bounding box on the image\n",
    "# cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)  # Green color, thickness 2\n",
    "\n",
    "# # Display or save the image with the bounding box\n",
    "# cv2.imshow('Image with Bounding Box', image)\n",
    "# cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "# cv2.destroyAllWindows()  # Clean up windows\n",
    "# image = cv2.imread('your_image.jpg')\n",
    "if image is not None:\n",
    "    # Draw bounding box and display the image\n",
    "    cv2.rectangle(image, (int(x*640), int(y*640)), (int((x+w)*640), int((y+h)*640)), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('LSTM-Prediction', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Image could not be loaded!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
